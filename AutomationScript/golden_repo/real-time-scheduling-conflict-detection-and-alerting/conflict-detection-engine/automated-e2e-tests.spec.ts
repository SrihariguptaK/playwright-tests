json
{
  "success": true,
  "playwrightTests": [
    {
      "storyId": "story-15",
      "storyTitle": "As Scheduler, I want the system to log all detected conflicts with timestamps and metadata for audit and analysis",
      "testFile": "conflict-logging.spec.ts",
      "testCode": "import { test, expect } from '@playwright/test';\n\ntest.describe('Story-15: Conflict Logging with Timestamps and Metadata', () => {\n  const API_BASE_URL = process.env.API_BASE_URL || 'http://localhost:3000';\n  let authToken: string;\n\n  test.beforeEach(async ({ page }) => {\n    // Login to get authentication token\n    await page.goto(`${API_BASE_URL}/login`);\n    await page.fill('[data-testid=\"username-input\"]', 'scheduler@test.com');\n    await page.fill('[data-testid=\"password-input\"]', 'password123');\n    await page.click('[data-testid=\"login-button\"]');\n    await page.waitForURL('**/dashboard');\n    \n    // Extract auth token from localStorage or cookies\n    authToken = await page.evaluate(() => localStorage.getItem('authToken') || '');\n  });\n\n  test('Verify logging of detected conflicts with metadata (happy-path)', async ({ page, request }) => {\n    // Step 1: Create two overlapping bookings for the same resource to trigger a conflict\n    await page.goto(`${API_BASE_URL}/bookings/create`);\n    \n    // Create first booking\n    await page.fill('[data-testid=\"resource-select\"]', 'conference-room-a');\n    await page.fill('[data-testid=\"booking-start-time\"]', '2024-01-15T10:00');\n    await page.fill('[data-testid=\"booking-end-time\"]', '2024-01-15T12:00');\n    await page.fill('[data-testid=\"booking-user\"]', 'user1@test.com');\n    await page.click('[data-testid=\"create-booking-button\"]');\n    await expect(page.locator('[data-testid=\"success-message\"]')).toBeVisible();\n    const firstBookingId = await page.locator('[data-testid=\"booking-id\"]').textContent();\n    \n    // Create second overlapping booking for same resource\n    await page.goto(`${API_BASE_URL}/bookings/create`);\n    await page.fill('[data-testid=\"resource-select\"]', 'conference-room-a');\n    await page.fill('[data-testid=\"booking-start-time\"]', '2024-01-15T11:00');\n    await page.fill('[data-testid=\"booking-end-time\"]', '2024-01-15T13:00');\n    await page.fill('[data-testid=\"booking-user\"]', 'user2@test.com');\n    await page.click('[data-testid=\"create-booking-button\"]');\n    \n    // Expected Result: Conflict logged with timestamp and metadata\n    await expect(page.locator('[data-testid=\"conflict-detected-message\"]')).toBeVisible();\n    const secondBookingId = await page.locator('[data-testid=\"booking-id\"]').textContent();\n    \n    // Step 2: Verify that the conflict is logged automatically\n    await page.goto(`${API_BASE_URL}/conflict-logs`);\n    await page.waitForSelector('[data-testid=\"conflict-log-table\"]');\n    \n    // Step 3: Check that the log entry contains an accurate timestamp\n    const logEntry = page.locator('[data-testid=\"conflict-log-entry\"]').first();\n    await expect(logEntry.locator('[data-testid=\"log-timestamp\"]')).toBeVisible();\n    const timestamp = await logEntry.locator('[data-testid=\"log-timestamp\"]').textContent();\n    expect(timestamp).toBeTruthy();\n    expect(new Date(timestamp || '').getTime()).toBeLessThanOrEqual(Date.now());\n    \n    // Step 4: Verify log entry includes metadata for involved bookings\n    await expect(logEntry.locator('[data-testid=\"booking-ids\"]')).toContainText(firstBookingId || '');\n    await expect(logEntry.locator('[data-testid=\"booking-ids\"]')).toContainText(secondBookingId || '');\n    await expect(logEntry.locator('[data-testid=\"booking-times\"]')).toBeVisible();\n    await expect(logEntry.locator('[data-testid=\"user-information\"]')).toContainText('user1@test.com');\n    await expect(logEntry.locator('[data-testid=\"user-information\"]')).toContainText('user2@test.com');\n    \n    // Step 5: Verify log entry includes resource information\n    await expect(logEntry.locator('[data-testid=\"resource-id\"]')).toBeVisible();\n    await expect(logEntry.locator('[data-testid=\"resource-name\"]')).toContainText('conference-room-a');\n    await expect(logEntry.locator('[data-testid=\"resource-type\"]')).toBeVisible();\n    \n    // Step 6: Verify detection rule version is recorded\n    await expect(logEntry.locator('[data-testid=\"detection-rule-version\"]')).toBeVisible();\n    const ruleVersion = await logEntry.locator('[data-testid=\"detection-rule-version\"]').textContent();\n    expect(ruleVersion).toMatch(/v\\d+\\.\\d+\\.\\d+/);\n    \n    // Step 7: Send GET request to /api/conflict-logs endpoint\n    const apiResponse = await request.get(`${API_BASE_URL}/api/conflict-logs`, {\n      headers: {\n        'Authorization': `Bearer ${authToken}`,\n        'Content-Type': 'application/json'\n      }\n    });\n    \n    // Expected Result: Log entry retrieved with complete details\n    expect(apiResponse.ok()).toBeTruthy();\n    const logsData = await apiResponse.json();\n    expect(logsData).toBeTruthy();\n    expect(Array.isArray(logsData)).toBeTruthy();\n    \n    // Step 8: Query logs using conflict ID or timestamp\n    const conflictId = await logEntry.locator('[data-testid=\"conflict-id\"]').textContent();\n    const specificLogResponse = await request.get(`${API_BASE_URL}/api/conflict-logs?conflictId=${conflictId}`, {\n      headers: {\n        'Authorization': `Bearer ${authToken}`,\n        'Content-Type': 'application/json'\n      }\n    });\n    \n    // Step 9: Verify retrieved log entry matches expected data structure\n    expect(specificLogResponse.ok()).toBeTruthy();\n    const specificLog = await specificLogResponse.json();\n    expect(specificLog).toHaveProperty('timestamp');\n    expect(specificLog).toHaveProperty('bookings');\n    expect(specificLog).toHaveProperty('resources');\n    expect(specificLog).toHaveProperty('detectionRuleVersion');\n    expect(specificLog.bookings).toHaveLength(2);\n    \n    // Step 10: Initiate export operation for conflict logs\n    await page.click('[data-testid=\"export-logs-button\"]');\n    await page.selectOption('[data-testid=\"export-format-select\"]', 'json');\n    \n    // Step 11: Download exported log file\n    const downloadPromise = page.waitForEvent('download');\n    await page.click('[data-testid=\"confirm-export-button\"]');\n    const download = await downloadPromise;\n    \n    // Expected Result: Logs exported successfully in requested format\n    expect(download.suggestedFilename()).toContain('conflict-logs');\n    expect(download.suggestedFilename()).toContain('.json');\n    \n    // Step 12: Verify exported file contains conflict log entry with all metadata\n    const downloadPath = await download.path();\n    expect(downloadPath).toBeTruthy();\n  });\n\n  test('Ensure logging does not impact detection performance (edge-case)', async ({ page, request }) => {\n    const conflictScenarios = [];\n    const latenciesWithLogging: number[] = [];\n    const latenciesWithoutLogging: number[] = [];\n    \n    // Step 1: Ensure logging feature is enabled\n    await page.goto(`${API_BASE_URL}/admin/settings`);\n    await page.check('[data-testid=\"enable-conflict-logging-checkbox\"]');\n    await page.click('[data-testid=\"save-settings-button\"]');\n    await expect(page.locator('[data-testid=\"settings-saved-message\"]')).toBeVisible();\n    \n    // Step 2: Prepare 10 conflict scenarios\n    for (let i = 0; i < 10; i++) {\n      conflictScenarios.push({\n        resource: `test-resource-${i}`,\n        booking1: {\n          startTime: `2024-01-${15 + i}T10:00`,\n          endTime: `2024-01-${15 + i}T12:00`,\n          user: `user1-${i}@test.com`\n        },\n        booking2: {\n          startTime: `2024-01-${15 + i}T11:00`,\n          endTime: `2024-01-${15 + i}T13:00`,\n          user: `user2-${i}@test.com`\n        }\n      });\n    }\n    \n    // Step 3: Clear existing performance metrics\n    await page.goto(`${API_BASE_URL}/admin/performance`);\n    await page.click('[data-testid=\"clear-metrics-button\"]');\n    await expect(page.locator('[data-testid=\"metrics-cleared-message\"]')).toBeVisible();\n    \n    // Step 4-6: Trigger conflict detection and measure latency with logging enabled\n    for (let i = 0; i < conflictScenarios.length; i++) {\n      const scenario = conflictScenarios[i];\n      const startTime = Date.now();\n      \n      // Create first booking\n      const booking1Response = await request.post(`${API_BASE_URL}/api/bookings`, {\n        headers: {\n          'Authorization': `Bearer ${authToken}`,\n          'Content-Type': 'application/json'\n        },\n        data: {\n          resource: scenario.resource,\n          startTime: scenario.booking1.startTime,\n          endTime: scenario.booking1.endTime,\n          user: scenario.booking1.user\n        }\n      });\n      expect(booking1Response.ok()).toBeTruthy();\n      \n      // Create second overlapping booking to trigger conflict\n      const booking2Response = await request.post(`${API_BASE_URL}/api/bookings`, {\n        headers: {\n          'Authorization': `Bearer ${authToken}`,\n          'Content-Type': 'application/json'\n        },\n        data: {\n          resource: scenario.resource,\n          startTime: scenario.booking2.startTime,\n          endTime: scenario.booking2.endTime,\n          user: scenario.booking2.user\n        }\n      });\n      \n      const endTime = Date.now();\n      const latency = endTime - startTime;\n      latenciesWithLogging.push(latency);\n    }\n    \n    // Step 7: Calculate average detection latency with logging enabled\n    const avgLatencyWithLogging = latenciesWithLogging.reduce((a, b) => a + b, 0) / latenciesWithLogging.length;\n    \n    // Step 8: Verify average latency remains within 2 seconds\n    expect(avgLatencyWithLogging).toBeLessThanOrEqual(2000);\n    \n    // Step 9: Verify individual latencies do not exceed 2 seconds\n    for (const latency of latenciesWithLogging) {\n      expect(latency).toBeLessThanOrEqual(2000);\n    }\n    \n    // Step 10: Disable logging feature\n    await page.goto(`${API_BASE_URL}/admin/settings`);\n    await page.uncheck('[data-testid=\"enable-conflict-logging-checkbox\"]');\n    await page.click('[data-testid=\"save-settings-button\"]');\n    await expect(page.locator('[data-testid=\"settings-saved-message\"]')).toBeVisible();\n    \n    // Step 11: Clear performance metrics again\n    await page.goto(`${API_BASE_URL}/admin/performance`);\n    await page.click('[data-testid=\"clear-metrics-button\"]');\n    await expect(page.locator('[data-testid=\"metrics-cleared-message\"]')).toBeVisible();\n    \n    // Step 12: Trigger same conflict scenarios without logging\n    for (let i = 0; i < conflictScenarios.length; i++) {\n      const scenario = conflictScenarios[i];\n      const startTime = Date.now();\n      \n      // Create first booking\n      const booking1Response = await request.post(`${API_BASE_URL}/api/bookings`, {\n        headers: {\n          'Authorization': `Bearer ${authToken}`,\n          'Content-Type': 'application/json'\n        },\n        data: {\n          resource: `${scenario.resource}-no-log`,\n          startTime: scenario.booking1.startTime,\n          endTime: scenario.booking1.endTime,\n          user: scenario.booking1.user\n        }\n      });\n      expect(booking1Response.ok()).toBeTruthy();\n      \n      // Create second overlapping booking\n      const booking2Response = await request.post(`${API_BASE_URL}/api/bookings`, {\n        headers: {\n          'Authorization': `Bearer ${authToken}`,\n          'Content-Type': 'application/json'\n        },\n        data: {\n          resource: `${scenario.resource}-no-log`,\n          startTime: scenario.booking2.startTime,\n          endTime: scenario.booking2.endTime,\n          user: scenario.booking2.user\n        }\n      });\n      \n      const endTime = Date.now();\n      const latency = endTime - startTime;\n      latenciesWithoutLogging.push(latency);\n    }\n    \n    // Step 13: Calculate average latency without logging\n    const avgLatencyWithoutLogging = latenciesWithoutLogging.reduce((a, b) => a + b, 0) / latenciesWithoutLogging.length;\n    \n    // Step 14: Compare average latencies\n    const absoluteDifference = Math.abs(avgLatencyWithLogging - avgLatencyWithoutLogging);\n    const percentageDifference = (absoluteDifference / avgLatencyWithoutLogging) * 100;\n    \n    // Step 15: Verify performance difference is not significant\n    // Expected Result: Less than 10% degradation or less than 200ms absolute difference\n    expect(percentageDifference).toBeLessThan(10);\n    expect(absoluteDifference).toBeLessThan(200);\n    \n    // Step 16: Document performance test results\n    console.log(`Performance Test Results:`);\n    console.log(`Average latency with logging: ${avgLatencyWithLogging.toFixed(2)}ms`);\n    console.log(`Average latency without logging: ${avgLatencyWithoutLogging.toFixed(2)}ms`);\n    console.log(`Absolute difference: ${absoluteDifference.toFixed(2)}ms`);\n    console.log(`Percentage difference: ${percentageDifference.toFixed(2)}%`);\n    \n    // Verify documentation is accessible\n    await page.goto(`${API_BASE_URL}/admin/performance`);\n    await expect(page.locator('[data-testid=\"performance-metrics-table\"]')).toBeVisible();\n  });\n});"
    }
  ]
}